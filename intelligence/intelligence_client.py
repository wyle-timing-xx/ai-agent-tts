from typing import Optional
from openai import OpenAI, Stream
from openai.types.chat import ChatCompletionChunk
from tts.tts import TTS
from intelligence.intelligence import Intelligence


class OpenAIIntelligence(Intelligence):
    def __init__(
        self,
        api_key: str,
        tts: TTS,
        base_url: Optional[str] = "https://api.openai.com/v1",
        model: Optional[str] = None,
    ):
        self.client = OpenAI(
            base_url=base_url,
            api_key=api_key,
            max_retries=3,
        ).chat

        self.tts = tts
        self.system_prompt = "You are AI Interviewer and you are interviewing a candidate for a software engineering position."
        self.chat_history = []
        self.model = model or "gpt-3.5-turbo"

    def build_messages(
        self,
        text: str,
        sender_name: str,
    ):
        # TODO: generate context related to text
        # RAG
        context = ""

        # Build the message
        human_message = {
            "role": "user",
            "type": "human",
            "name": sender_name.replace(" ", "_"),
            "content": text,
        }

        # Add message to history
        self.chat_history.append(human_message)

        # Local chat history limited to few messages
        chat_history = []

        # Add system message and generated context
        chat_history.append(
            {
                "role": "system",
                "type": "system",
                "content": self.system_prompt,
            }
        )

        # Add few messages from global history
        chat_history = chat_history + self.chat_history[-20:]

        # Return local chat history
        return chat_history

    def add_response(self, text):
        ai_message = {
            "role": "assistant",
            "type": "ai",
            "name": "Interviewer",
            "content": text,
        }

        self.chat_history.append(ai_message)

    def text_generator(self, response: Stream[ChatCompletionChunk]):
        for chunk in response:
            content = chunk.choices[0].delta.content
            if content:
                yield content

    def generate(self, text: str, sender_name: str):
        # build old history
        messages = self.build_messages(text, sender_name=sender_name)

        # generate llm completion
        response = self.client.completions.create(
            model=self.model,
            messages=messages,
            max_tokens=100,
            temperature=0.5,
            stream=False,
        )
        response_text = ""

        # TODO: handle stream response and generate text chunk by chunk
        # text_iterator = self.text_generator(response)
        # self.tts.generate(text=text_iterator)

        # generate text as a block
        response_text = response.choices[0].message.content
        self.tts.generate(text=response_text)

        print(f"[Interviewer]: {response_text}")

        # add response to history
        self.add_response(response_text)
